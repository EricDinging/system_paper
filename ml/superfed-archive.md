# [SuperFed: Weight Shared Federated Learning](https://arxiv.org/abs/2301.10879)
## Problem
- Produce multiple model in training for on-device inference
- Explore trade-off between efficiency and accuracy
- Training multiple models independently is cost-prohibitive
## Backgrounds

## Challenges


## Observations

## Ideas
- Co-trains a family of model variants in a federated fashion simultaneously by leveraging weight sharing.
- After training, the clients perform local neural architecture search to find the appropiate model variants.
## Contribution

## Methods

## Results

## Application

## Limitation

## Questions